{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Chorse Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Probability and statisitcs\n",
    "4. Hypothesis Testing &nbsp; [1](http://localhost:8888/notebooks/Modeling/AB_testing_morning_students.ipynb) &nbsp;[2](http://localhost:8888/notebooks/Modeling/AB_testing_afternoon.ipynb)\n",
    "2. SQL\n",
    "3. Sampling and Estimating\n",
    "5. Power Calculation and Bayes\n",
    "6. Linear Regression\n",
    "7. Cross Validation and Regularization\n",
    "8. Logistic Regression\n",
    "9. Decision Trees and KNN\n",
    "10. Bagging and Random Forest\n",
    "11. SVM and Kernels [1](http://localhost:8888/notebooks/Modeling/support-vector-machines-fonnesbeck.ipynb)\n",
    "12. Boosting&nbsp;[1](http://localhost:8888/notebooks/Modeling/boosting-drury.ipynb)\n",
    "16. Kmeans and Hierarchical Clustering [1](http://localhost:8888/notebooks/Modeling/Hierarchical_Clustering.ipynb)\n",
    "15. Neural Nets\n",
    "17. Dimensionality Reduction, PCA, and SVD [SVD](http://localhost:8888/notebooks/Modeling/svd-example-blank.ipynb)\n",
    "19. Non-negative Matrix Factorization (NMF) [1](http://localhost:8888/notebooks/Modeling/nmf_pres.ipynb)\n",
    "20. Natural Language Processing\n",
    "13. Web Scraping\n",
    "14. Mongo DB\n",
    "18. Map reduce and Profit Curve\n",
    "20. AWS\n",
    "21. Spark\n",
    "22. Spark ML\n",
    "23. Recommendation System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Probability and Statistics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Probability </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Value: &nbsp;&nbsp;&nbsp;&nbsp;$\\sum(X) = x_1*p_1 + x_2*p_2 ..... +x_n*p_n$\n",
    "\n",
    "\n",
    "Variance =&nbsp;&nbsp;&nbsp;&nbsp; $\\sum_{i=1}^k = p_i * (x_i - \\mu)^2$\n",
    "\n",
    "\n",
    "\n",
    "COV(X,Y) = &nbsp;&nbsp;&nbsp;&nbsp;$E(X Y)-E(X)E(Y)$\n",
    "\n",
    "\n",
    "\n",
    "P(A $\\bigcap$ B)&nbsp;&nbsp;&nbsp;&nbsp; = $P(A|B) * P(B)\n",
    "                = P(B|A) * P(A)$\n",
    "         \n",
    "         \n",
    "                \n",
    "Bayes Theorm:&nbsp;&nbsp;&nbsp;&nbsp; $P(B|A) =  \\frac{P(A|B) * P(B)}{P(A)}$\n",
    "\n",
    "\n",
    "\n",
    "Permutations =&nbsp;&nbsp;&nbsp;&nbsp;$P(n,k)=\\dfrac{n!}{(n-k)!}$\n",
    "\n",
    "\n",
    "\n",
    "Combinations =&nbsp;&nbsp;&nbsp;&nbsp; $C(n,k)={{n}\\choose{k}} = {{n!}\\over{(n-k)!k!}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Probability Distributions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Discrete </h3>\n",
    "\n",
    "X ~ $Bernoulli$: single coin flip turns out to be heads\n",
    "\n",
    "X ~ $Binomial(n,p)$: number of coin flips out of n that thurn out to be heads\n",
    "\n",
    "X ~ $Geometric(p)$: number traials until a coin flip turns out to be heads\n",
    "\n",
    "X ~ $Poisson(\\lambda=5)$: number of customers arriving in a coffee shop in a give time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Continuous</h3>\n",
    "\n",
    "X ~ $Exponential(\\lambda=5)$: time until customer will arrive at the coffee shop\n",
    "\n",
    "X ~ $Uniform(a=0, b=360)$: locatoin of the hour or minute hand (in degrees) on a clock\n",
    "\n",
    "X ~ $Gaussian(\\mu=100, \\sigma=15)$: IQ Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Discrete Formulas </h3>\n",
    "\n",
    "$Binomial:  P(X=k) = \\binom{n}{k}p^k(1-p)^{k-1}p$\n",
    "\n",
    "$Poisson: P(X=k) = \\frac{\\lambda^ke^{-\\lambda}}{k!}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Continuous Formulas</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Eponential: f(x)=\\lambda*e^{-\\lambda}, x>=0$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  $E(X) = \\frac{1}{\\lambda}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Statistics and Hypothesis testing </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Central Limit Theorm:</b><p> The CLT says that the mean of a sufficiently $(>30)$ large number of i.i.d random variables will be approximately normal!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hypothesis Testing</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. State the null hypothesis $(H_0)$ and the alternative hypothesis $(H_A)$\n",
    "2. Choose the significance level, $\\alpha$\n",
    "3. Compute the appropriate test statistic\n",
    "4. Compute the p-values under the assumption that $H_0$ is true\n",
    "    1. if p-value $<= \\alpha \\to$ Reject $H_0$ in favor of $H_A$\n",
    "    2. if p-value $>= \\alpha \\to$ Reject $H_0$ in favor of $H_A$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>significance level ($\\alpha$)</b>: Is the proabability of rejecting the null hypothesis\n",
    "\n",
    "\n",
    "- <b>p-value</b>: The p-value is defined as the probability, under the null hypothesis, of obtaining a result equal to or more extreme than what was actually observed. \n",
    "\n",
    "\n",
    "- <b>Hypothesis errors Errors</b>:\n",
    "    1. Type 1 error: Rejecting $H_0$ when it is true\n",
    "    2. Type 2 error: Falling to reject $H_0$ when it is false\n",
    "    \n",
    "    \n",
    "- <b>Test Statistic</b>: $z = \\frac{\\bar{x}-\\mu_0}{\\sigma_0/\\sqrt{n}}$\n",
    "\n",
    "\n",
    "- <b>Bonferroni Correction</b>: When making mulitple comparisons, need to adjust sign rates of indiviual tests.\n",
    "    - $\\alpha_i = \\frac{\\alpha_E}{m}$\n",
    "    - $m$ is the number of comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example code from scipy stats for a ttest</b>\n",
    "\n",
    "```scipy.stats.ttest_ind(a, b, equal_var = False)```\n",
    "\n",
    "- What is the $P(90<X<95)$ where μμ = 80, σσ = 12?\n",
    "\n",
    "        import scipy.stats as stats\n",
    "        disn = stats.norm(loc=80,scale=12)\n",
    "        disn.cdf(95) - disn.cdf(90)\n",
    "        0.096678607296787789\n",
    "        \n",
    "- <b> Binomial Test </b>\n",
    "\n",
    "    ```print(\"binomial test - %s\"%st.binom_test(h, n, p))```\n",
    "\n",
    "<b>Link to more example code, [Click here](http://file:///Users/jacobshomer/Desktop/Galvanize/power-bayesian/html/review.html)</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Power </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\alpha$ = Type I Error\n",
    "- $\\beta$ = Type II Error\n",
    "- $1-\\beta$ = Power - Reject $H_0$ when $H_0$ is False\n",
    "\n",
    "\n",
    "* Power determines the number of smples needed to power a given study\n",
    "* The likelihood that we call something significant when there is something there ot be deteted \n",
    "\n",
    "<b>Things that affect our statistical power</b>\n",
    "1. Significance level\n",
    "2. $|\\mu_0- \\mu_1|$\n",
    "3. Standard deviation \n",
    "4. Sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Power](https://i.pinimg.com/originals/47/25/2f/47252f82c782ff42864902deb188e7bc.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Linear Regression</h2>\n",
    "\n",
    "[link_to_notebook](http://localhost:8888/notebooks/Modeling/EDA%2Blinear_regression_intro.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Logistic Regression </h2>\n",
    "\n",
    "[link_to_notebook](http://localhost:8888/notebooks/Modeling/Linear_logistic.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Cross Validation and Regularization </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is regression??</b>\n",
    "\n",
    "- Use features to predict real valued targets\n",
    "    -future sales/revenue\n",
    "\n",
    "<b>What is Classification</b>\n",
    "\n",
    "- use features to predict cateorical targets\n",
    "    - yes/no, 0-9\n",
    "    \n",
    "<b>Underfitting </b>\n",
    "- The model doesnt't fully capture the relationship between predictor and the target\n",
    "- Has not learned the data's signal\n",
    "\n",
    "     -<b>signal</b> is that what we want to model\n",
    "\n",
    "<b>Overfitting:</b>\n",
    "- The model has tried to capture the sampling error\n",
    "- Has learned the data's signal and the noise\n",
    "\n",
    "     -<b>noise</b> is that what we don't want to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>K-Fold</h3>\n",
    "\n",
    "1.Split data set into k 'folds'\n",
    "2. Train using (k-1) folds. Validate on the left out fold. Record validation.\n",
    "3. Train k models, leaving a different fold out each time\n",
    "4. Average the validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![K_fold](k-fold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bias/Variance Trade off</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <b>Bias</b>: the amount the expected value of the results differs from the true value\n",
    "    - $Bias[\\hat{f}(x)] = E[\\hat{f}(x) - f(x)]$\n",
    "    \n",
    "2. <b>Variance</b>: the expected value of the squared deviation of the results from the mean of the results. In other words, the spread of the square difference from the mean\n",
    "\n",
    "    - $Var[\\hat{f}(x)] = E[\\hat{f}(x)^2] - E[f(x)]^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A low bias model accurately predicts the populations's underlying true value, or signal\n",
    "\n",
    "\n",
    "- A low variance model's predictions dont't change much when it is fit on different data from the underlying population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bias_variance](bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cross Validation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A technique for assess how the results of statistical analysis will generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](onecross_val.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Modeling <h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>General Modeling Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Curse of Dimensionality</b>: as the number of parameters increases the model the data points need increases exponentially\n",
    "\n",
    "   --Sampling density is proportional to $N^{\\frac{1}{D}}$\n",
    "   \n",
    "<b>Regularization</b>: is the processes of restricing our model to reduce its variance and complexity (number of features)\n",
    "\n",
    "<b>Non-Parametric</b>: \n",
    "\n",
    "        -The structure is not specified beforehand, it is determinded from the data\n",
    "        -Models population cannot be described in advanced\n",
    "        -Applicability is wider\n",
    "        -In cases where parametric models are appropriate, non_parametrics have less power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parametric     | Non-Parametric           | \n",
    "| ------------- |:-------------:|\n",
    "|Simple/easy to understand interpret | Flexible |\n",
    "| fast to predict  | No assumption about the functional form  |\n",
    "| Don't need as mcuh data | Good performance    | \n",
    "|Constrained, bias| More Data!|\n",
    "|Poor perfromance if model assumptions do not hold|  Easily overfit |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regularization</h3>\n",
    "\n",
    "<b>Linear Regression</b>: $Y = \\beta_0 +\\beta_1X_1+...+\\beta_pX_p + \\epsilon $\n",
    "\n",
    "Estimation of parameter by minimizing:  $\\sum_{i=1}^{N}(y_i-\\hat{\\beta_0}-\\sum_{j=1}^{p}X_{ij}\\hat{\\beta_j})^2$\n",
    "\n",
    "<b>Regularized Linear Regression</b>: $Y = \\beta_0 +\\beta_1X_1+...+\\beta_pX_p + \\epsilon $\n",
    "\n",
    "Estimation of parameter by minimizing:  $\\sum_{i=1}^{N}(y_i-\\hat{\\beta_0}-\\sum_{j=1}^{p}X_{ij}\\hat{\\beta_j})^2 +\\lambda\\sum_{j=1}^{p}|\\hat{\\beta_j}|^L$\n",
    "\n",
    "Why? Changing $\\lambda$ changes the amount that large coefficients are penalized. Increasing $\\lambda$ increases the model's bas and decreases its variance\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Descision Trees</h2>\n",
    "![descision_tree](descision_tree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Decision trees are a supervised, non_parametrics learners that preforms a series of binary splits with the goal of minimizing predictive error. The key point is that each split is determined by the information gain of the split.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Pros        | Cons           | \n",
    "| ------------- |:-------------:|\n",
    "|non-parametric, non-linear      | expensive to train |\n",
    "| classification or regression     | greedy algorithm (local maxima)  |\n",
    "| easy to interpret | Overfits easy    | \n",
    "|computationally cheap predictions| deterministic|\n",
    "|multicollinearity|   |\n",
    "\n",
    "\n",
    "<i><b>Deterministic</b> is that you will get teh same model on the same training data, whether it is good or bad</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>How to split</h3>\n",
    "\n",
    "1. Calculate the information gain for all possible splits\n",
    "2. Commit the split that has the highest information gain\n",
    "\n",
    "Shannon Entropy: $H(X) = -\\sum p_ilog_2(p_i)$ \n",
    "\n",
    "        p_i: probability of each possible discrete outcome\n",
    "\n",
    "<b>Information Gain</b> $IG(S,C) = H(S) - \\sum_{C_i\\in C}\\frac{|C_i|}{|S|}H(C_i) $\n",
    "\n",
    "$S$ = The parent's set of samples\n",
    "\n",
    "$C$ = the set of children\n",
    "\n",
    "$C_i$ = the set of samples in each child\n",
    "\n",
    "$H$ = entropy of child i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preventing Overfitting (Pruning)</h3>\n",
    "\n",
    "-Leaf size: stop sploitting when number of samples gets small enough\n",
    "\n",
    "-Depth: stop splitting at a certain depth\n",
    "\n",
    "-purity: stop splitting if enough of the examples are the sme class\n",
    "\n",
    "-gain threshold: stop splitting when the info gain is too small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>K Nearest Neighbors (KNN)</h2>\n",
    "\n",
    "![knn](knn.png)\n",
    "\n",
    "\n",
    "[Link_To_notebook](http://localhost:8888/notebooks/Modeling/knn_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>KNN Classification</b>: The output is class membership. Each sample is assigned ot the class nearest to it\n",
    "\n",
    "<b>KNN regression</b>: The output is the predicted value for the sample. This value is the average of teh values of <i>k</i> nearest training samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm:\n",
    "\n",
    "    1. Calculate the distance from x to all points in your dataset\n",
    "    2. Sort the points in your dataset by increasing distance from x\n",
    "    3. Predict the majority (mode) label of the k nearest points (or average of k if regression)\n",
    "    \n",
    "<b>Distance Metrics</b>\n",
    "\n",
    "Euclidean Dist (L2): $\\sqrt{\\sum_{i=1}^n(q_i-p_i)^2}$\n",
    "\n",
    "Manhattan Distance(L1): $\\sum_{i=1}^n|q_i-p_i|$\n",
    "\n",
    "Cosince Distance = 1 - Cosine Similarity = $1- \\frac{a*b}{||a||*||b||}$\n",
    "\n",
    "<b>Hyperparameter</b> The only hyperparameter is k. As as rule of thumb start with $k = \\sqrt{n}$\n",
    "\n",
    "\n",
    "\n",
    "<b>Curse of Dimensionality</b>: KNN will suffer in high dimensions. It takes much data to make up for increased dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Pros        | Cons           | \n",
    "| ------------- |:-------------:|\n",
    "|super-simple     | high prediction cost |\n",
    "| works with any number of classes     | High dimns= poor performance  |\n",
    "| easy to add data | Categorical features don't work well   | \n",
    "|few hyperparameters|\n",
    "|multicollinearity|  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Ensemble, Bagging and Random Forest </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Ensemble</h3>\n",
    "\n",
    "-Combine multiple weak learners to make a strong learner\n",
    " \n",
    "    1. Train muliple models on the data\n",
    "    2. predict and take the average of the different models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bootstrapping and Bagging</h3>\n",
    "\n",
    "-Given a sample of n data points, we take B bootstrapped samples of our data with replacement\n",
    "-We can use it to get a confidence intervals around a statistic/parameter\n",
    "\n",
    "<b>Bagging (boostrap aggregation)</b>: We need independent sample to train our models on!\n",
    "\n",
    "    1.Draw new samples from our population ( or bootstrap)\n",
    "    2. Train a model on each new sample\n",
    "    3. Average the predictions from each (aggregating)\n",
    "    \n",
    "\n",
    "-General purpose methon for reducing the variance\n",
    "\n",
    "-Trees are most comming. Grow them deep -- high variance, low bias\n",
    "\n",
    "-Aggregating the ouputs gives us large reduction in variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest</h3>\n",
    "\n",
    "-improves over bagging becase each tree is decorrelated. \n",
    "-Each split only m featurns are selected $m = sqrt(p)$\n",
    "\n",
    "<b>hyperparameters</b>:\n",
    "\n",
    "-Number of trees in the forest = n_estimators\n",
    "\n",
    "-Information gain metric = criterion\n",
    "\n",
    "-Number of features to consider for split = max_features\n",
    "\n",
    "\n",
    "<b>Out of bag Score</b>: a quick replacment for cross validation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Support Vecotor Machine (SVM) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Boosting </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3> General idea </h3>\n",
    "\n",
    "- <b> An ensemble of trees are groun sequentially based on the information learned from prevous tree</b>\n",
    "\n",
    "    1. Each tree is fit on some modified verions of the training set based on the previous resluts\n",
    "    2. In <b>adaboost</b> the datapoints associated with the largest residuals are weighted the most in the new training set.\n",
    "    \n",
    "    3. in <b>gradient Boosting</b> the new training set is the residulas\n",
    "\n",
    "\n",
    "\n",
    "- The different between averaging methonds (random forest, bagging) and boosting\n",
    "    - With averaging models you take multiple weak learners and average the predictions\n",
    "    \n",
    "    - With boosting, high bias models are built seqentially on top of each other\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>KMeans</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hierarchical Clustering </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Nets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dimensionality Reduction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Non-negative Matrix Factorization (NMF)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dimensionality Reduction, PCA, and SVD</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Non-negative Matrix Factorization (NMF)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Profit Curve</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Bases</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SQL</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Postgres SQL</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mongo DB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Web Scrapping </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>AWS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Spark</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Spark ML</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recommendation System</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
